import streamlit as st
import requests
import re
import random
import json
import sqlite3
import time
import html
import os
from typing import List, Dict, Any, Generator
from llama_index.core import VectorStoreIndex, StorageContext, Settings
from llama_index.core.vector_stores import MetadataFilters, MetadataFilter, FilterOperator
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from qdrant_client import QdrantClient
from openai import OpenAI
import urllib.request
import zipfile

def download_data_from_releases():
    # ä» secrets è¯»å–é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    repo = st.secrets.get("GITHUB_REPO", "lyf-Felicia/SeriesSearchApp")
    tag = st.secrets.get("RELEASE_TAG", "v1.0.0")
    # ä½¿ç”¨æ­£ç¡®çš„ GitHub Release URL æ ¼å¼
    release_base = f"https://github.com/{repo}/releases/download/{tag}"
    
    os.makedirs("data/database", exist_ok=True)
    os.makedirs("data/qdrant_data", exist_ok=True)
    
    files = {
        "data/llm_summaries.json": f"{release_base}/llm_summaries.json",
        "data/database/final.db": f"{release_base}/final.db",
        "data/qdrant_data.zip": f"{release_base}/qdrant_data.zip"
    }
    
    for local_path, url in files.items():
        # ä¼˜åŒ–åˆ¤æ–­é€»è¾‘ï¼šå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å° > 1KBï¼Œè·³è¿‡ä¸‹è½½
        # å¯¹äº zip æ–‡ä»¶ï¼Œæ£€æŸ¥è§£å‹åçš„ç›®å½•æ˜¯å¦å­˜åœ¨
        if local_path.endswith('.zip'):
            if os.path.exists("data/qdrant_data") and os.path.exists("data/qdrant_data/meta.json"):
                continue
        elif os.path.exists(local_path) and os.path.getsize(local_path) > 1024:
            continue
            
        try:
            with st.spinner(f"æ­£åœ¨ä¸‹è½½ {os.path.basename(local_path)}..."):
                # ä½¿ç”¨è‡ªå®šä¹‰ Header æ¨¡æ‹Ÿæµè§ˆå™¨ï¼Œé˜²æ­¢è¢« GitHub æ‹¦æˆª
                opener = urllib.request.build_opener()
                opener.addheaders = [('User-agent', 'Mozilla/5.0')]
                urllib.request.install_opener(opener)
                
                urllib.request.urlretrieve(url, local_path)
                
                # æ ¡éªŒï¼šå¦‚æœä¸‹è½½çš„æ–‡ä»¶å¤ªå°ï¼ˆå¯èƒ½æ˜¯ä¸‹è½½åˆ°äº†æŠ¥é”™é¡µé¢ï¼‰ï¼ŒæŠ›å‡ºå¼‚å¸¸
                if os.path.getsize(local_path) < 100:
                    with open(local_path, 'r') as f:
                        content = f.read()
                    st.error(f"ä¸‹è½½çš„æ–‡ä»¶å†…å®¹å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æ­£ç¡®ã€‚å†…å®¹ï¼š{content[:100]}")
                    continue

                if local_path.endswith('.zip'):
                    with zipfile.ZipFile(local_path, 'r') as zip_ref:
                        zip_ref.extractall("data/")
                    os.remove(local_path)
            st.toast(f"âœ“ {os.path.basename(local_path)} åŠ è½½æˆåŠŸ")
        except Exception as e:
            st.error(f"ä¸‹è½½å¤±è´¥ {local_path}: {str(e)}")

download_data_from_releases()

# ================= ğŸŸ¢ é…ç½®åŒºåŸŸ =================
# ä¼˜å…ˆä» Streamlit secrets è¯»å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
LLM_API_KEY = st.secrets.get("LLM_API_KEY", "sk-f193fd69ee8c47359a35325de4bf2a49")
LLM_BASE_URL = st.secrets.get("LLM_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
LLM_MODEL_NAME = st.secrets.get("LLM_MODEL_NAME", "qwen-max")
QDRANT_PATH = st.secrets.get("QDRANT_PATH", "data/qdrant_data")
EMBEDDING_MODEL_PATH = st.secrets.get("EMBEDDING_MODEL_PATH", "BAAI/bge-large-zh-v1.5")
DB_PATH = st.secrets.get("DB_PATH", "data/database/final.db")

# ==============================================================================
# 1. è¾…åŠ©å‡½æ•°ï¼šæ¸…ç†æ–‡æœ¬ä¸­çš„HTMLæ ‡ç­¾
# ==============================================================================
def clean_html_tags(text):
    """æ¸…ç†æ–‡æœ¬ä¸­çš„æ‰€æœ‰HTMLæ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬"""
    if not text:
        return ""
    # ç§»é™¤æ‰€æœ‰HTMLæ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', str(text))
    # è½¬ä¹‰å‰©ä½™çš„HTMLç‰¹æ®Šå­—ç¬¦
    text = html.escape(text)
    return text

def _render_turn_content(turn):
    """æ¸²æŸ“å•è½®å¯¹è¯çš„å†…å®¹ï¼ˆç”¨æˆ·æŸ¥è¯¢ã€AIæ¨èã€å‰§é›†åˆ—è¡¨ï¼‰"""
    # æ˜¾ç¤ºç”¨æˆ·æŸ¥è¯¢ï¼ˆå³ä¾§å¯¹é½ï¼‰
    with st.container():
        col_user_empty, col_user_content = st.columns([3, 7])
        with col_user_content:
            # æ¸…ç†å¹¶è½¬ä¹‰ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            user_text = clean_html_tags(turn.get('query', ''))
            st.markdown(f"""
            <div style="display: flex; justify-content: flex-end; margin: 0.75rem 0;">
                <div style="background: linear-gradient(135deg, #4f46e5, #6366f1); color: white; padding: 0.6rem 0.875rem; border-radius: 16px; border-bottom-right-radius: 4px; box-shadow: 0 2px 6px rgba(79, 70, 229, 0.2); max-width: 55%; word-wrap: break-word; line-height: 1.4; white-space: pre-wrap; font-size: 0.95em;">
                    {user_text}
                </div>
            </div>
            """, unsafe_allow_html=True)
    
    # æ˜¾ç¤ºAIæ¨èï¼ˆå·¦ä¾§å¯¹é½ï¼‰
    if turn.get('recommendation'):
        with st.container():
            col_ai_content, col_ai_empty = st.columns([7, 3])
            with col_ai_content:
                # æ¸…ç†å¹¶è½¬ä¹‰AIæ¨èæ–‡æœ¬
                ai_text = clean_html_tags(turn.get('recommendation', ''))
                st.markdown(f"""
                <div style="display: flex; justify-content: flex-start; margin: 0.75rem 0;">
                    <div style="background: #f8fafc; padding: 0.6rem 0.875rem; border-radius: 16px; border: 1px solid #e2e8f0; border-bottom-left-radius: 4px; box-shadow: 0 2px 6px rgba(0, 0, 0, 0.06); max-width: 55%; word-wrap: break-word; line-height: 1.4; white-space: pre-wrap; font-size: 0.95em;">
                        {ai_text}
                    </div>
                </div>
                """, unsafe_allow_html=True)
    
    # æ˜¾ç¤ºå‰§é›†åˆ—è¡¨ï¼ˆå·¦ä¾§å¯¹é½ï¼‰
    if turn.get('results'):
        st.markdown('<div style="padding: 0 1rem;">', unsafe_allow_html=True)
        for i, r in enumerate(turn['results']):
            with st.container(border=True):
                col_img, col_txt = st.columns([1, 3])
                with col_img:
                    st.image(fetch_poster_url(r['title']))
                with col_txt:
                    score = r.get('score', 0)
                    title = r.get('title', 'æœªçŸ¥')
                    year = r.get('year', 'æœªçŸ¥')
                    genre = r.get('genre', 'æœªçŸ¥')
                    region = r.get('region', 'æœªçŸ¥')
                    
                    # åŸºæœ¬ä¿¡æ¯ï¼ˆå§‹ç»ˆæ˜¾ç¤ºï¼‰
                    st.markdown(f"### ã€Š{title}ã€‹ <span style='color:grey;font-size:0.8em'>åŒ¹é…åº¦:{score:.2f}</span>", unsafe_allow_html=True)
                    st.markdown(f"<span style='color:#64748b;font-size:0.9em'>{year} Â· {genre} Â· {region}</span>", unsafe_allow_html=True)
                    
                    # è¯¦ç»†ä¿¡æ¯ï¼ˆå¯å±•å¼€ï¼‰
                    with st.expander("æŸ¥çœ‹è¯¦æƒ…", expanded=False):
                        # å®Œæ•´ç®€ä»‹
                        display_text = r.get('display_text', '')
                        if display_text:
                            st.markdown("**ç®€ä»‹ï¼š**")
                            st.write(display_text)
                        
                        # é«˜èƒ½å‰§æƒ…å‘½ä¸­
                        if r.get('matched_episodes'):
                            st.markdown("**é«˜èƒ½å‰§æƒ…å‘½ä¸­ï¼š**")
                            for ep in r['matched_episodes']:
                                st.success(f"ç¬¬{ep['ep_number']}é›†: {ep['content_snippet']}")
                        
                        # å…¶ä»–ä¿¡æ¯
                        st.markdown("**è¯¦ç»†ä¿¡æ¯ï¼š**")
                        col_info1, col_info2 = st.columns(2)
                        with col_info1:
                            st.text(f"å¹´ä»½: {year}")
                            st.text(f"ç±»å‹: {genre}")
                        with col_info2:
                            st.text(f"åœ°åŒº: {region}")
                            st.text(f"åŒ¹é…åº¦: {score:.2f}")
        st.markdown('</div>', unsafe_allow_html=True)

# ==============================================================================
# 2. è¾…åŠ©å‡½æ•°ï¼šå¿…åº”å®æ—¶æœå›¾
# ==============================================================================
@st.cache_data(ttl=3600)
def fetch_poster_url(query_title):
    """
    é€šè¿‡å¿…åº”æœç´¢è·å–æµ·æŠ¥ï¼ŒéªŒè¯å›¾ç‰‡å¯è®¿é—®æ€§
    """
    fallback_images = [
        "https://images.unsplash.com/photo-1536440136628-849c177e76a1?auto=format&fit=crop&w=500&q=60",
        "https://images.unsplash.com/photo-1485846234645-a62644f84728?auto=format&fit=crop&w=500&q=60",
    ]
    
    keyword = f"ç”µè§†å‰§ {query_title} æµ·æŠ¥"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    }

    def is_image_accessible(url):
        """éªŒè¯å›¾ç‰‡URLæ˜¯å¦å¯è®¿é—®"""
        try:
            response = requests.head(url, headers=headers, timeout=2, allow_redirects=True)
            return response.status_code == 200
        except:
            return False

    try:
        url = "https://cn.bing.com/images/search"
        params = {"q": keyword, "first": 1} 
        response = requests.get(url, params=params, headers=headers, timeout=3)
        
        if response.status_code == 200:
            html = response.text
            
            # 1. ä¼˜å…ˆæ‰¾ turl (ç¼©ç•¥å›¾)
            pattern_thumb = r'turl&quot;:&quot;(https://tse[^&]+?)&quot;'
            matches = re.findall(pattern_thumb, html)
            
            # éªŒè¯å‰5ä¸ªç¼©ç•¥å›¾
            for match in matches[:5]:
                if is_image_accessible(match):
                    return match
            
            # 2. å°è¯•åŸå›¾ murl
            pattern_full = r'murl&quot;:&quot;(http[^&]+?)&quot;'
            matches_full = re.findall(pattern_full, html)
            
            for match in matches_full[:3]:
                if is_image_accessible(match):
                    return match

    except Exception as e:
        pass

    return random.choice(fallback_images)

# ==============================================================================
# 2. åç«¯é€»è¾‘ SmartTVRetrieverï¼ˆä¿®æ”¹ç‰ˆï¼šæ”¯æŒå¤šé€‰ï¼‰
# ==============================================================================
class SmartTVRetriever:
    def __init__(self):
        try:
            print(f"æ­£åœ¨åŠ è½½æœ¬åœ° Embedding æ¨¡å‹: {EMBEDDING_MODEL_PATH} ...")
            self.embed_model = HuggingFaceEmbedding(model_name=EMBEDDING_MODEL_PATH, trust_remote_code=True)
            Settings.embed_model = self.embed_model
        except Exception as e:
            st.error(f"Embedding æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

        self.client = QdrantClient(path=QDRANT_PATH)
        self.rich_index = self._load_index("tv_series_rich_text")
        self.basic_index = self._load_index("tv_series_basic")
        
        print(f"æ­£åœ¨è¿æ¥ SQL æ•°æ®åº“: {DB_PATH} ...")
        self.conn = sqlite3.connect(DB_PATH, check_same_thread=False)
        self.conn.row_factory = sqlite3.Row 

        self.llm_client = OpenAI(api_key=LLM_API_KEY, base_url=LLM_BASE_URL)

    def _load_index(self, collection_name: str):
        vector_store = QdrantVectorStore(client=self.client, collection_name=collection_name)
        return VectorStoreIndex.from_vector_store(vector_store=vector_store)

    def filter_search(self, years: List[str] = None, genres: List[str] = None, 
                     regions: List[str] = None, limit: int = 10) -> List[Dict]:
        """ä¿®æ”¹ä¸ºæ”¯æŒå¤šé€‰çš„ç­›é€‰å‡½æ•°"""
        cursor = self.conn.cursor()
        sql = "SELECT * FROM series WHERE 1=1"
        params = []
        
        # å¹´ä»½å¤šé€‰å¤„ç†
        if years and len(years) > 0:
            year_conditions = []
            for year in years:
                if year == "æ›´æ—©":
                    year_conditions.append("CAST(year AS INTEGER) < 2018")
                else:
                    year_conditions.append("year = ?")
                    params.append(year)
            if year_conditions:
                sql += f" AND ({' OR '.join(year_conditions)})"
        
        # åœ°åŒºå¤šé€‰å¤„ç† - å¤„ç†"ä¸­å›½å¤§é™†"å’Œ"å¤§é™†"çš„æ˜ å°„
        if regions and len(regions) > 0:
            region_conditions_list = []
            for r in regions:
                if r == "ä¸­å›½å¤§é™†":
                    # "ä¸­å›½å¤§é™†"åŒæ—¶åŒ¹é…"ä¸­å›½å¤§é™†"å’Œ"å¤§é™†"
                    region_conditions_list.append("(region LIKE ? OR region LIKE ?)")
                    params.append("%ä¸­å›½å¤§é™†%")
                    params.append("%å¤§é™†%")
                else:
                    region_conditions_list.append("region LIKE ?")
                    params.append(f"%{r}%")
            
            if region_conditions_list:
                region_conditions = " OR ".join(region_conditions_list)
                sql += f" AND ({region_conditions})"
        
        # ç±»å‹å¤šé€‰å¤„ç†
        if genres and len(genres) > 0:
            genre_conditions = " OR ".join(["genre LIKE ?" for _ in genres])
            sql += f" AND ({genre_conditions})"
            params.extend([f"%{g}%" for g in genres])
            
        sql += " LIMIT ?"
        params.append(limit)
        
        try:
            cursor.execute(sql, params)
            rows = cursor.fetchall()
            
            results = []
            for row in rows:
                res_dict = {
                    "series_id": row['id'],
                    "title": row['title'],
                    "year": row['year'],
                    "genre": row['genre'],
                    "region": row['region'],
                    "source_type": "SQL",
                    "score": 1.0,
                    "actors": row['cast'] if 'cast' in row.keys() else "æš‚æ— æ¼”å‘˜ä¿¡æ¯",
                    "description": row['summary'] if 'summary' in row.keys() else "æš‚æ— å‰§æƒ…ç®€ä»‹"
                }
                results.append(res_dict)
            return results
        except sqlite3.Error as e:
            print(f"SQL Error: {e}")
            return []

    def _llm_rerank(self, query: str, candidates: List[Dict], top_k: int) -> List[Dict]:
        """åˆ©ç”¨å¤§æ¨¡å‹å¯¹åˆç­›ç»“æœè¿›è¡Œç²¾æ’"""
        if not candidates:
            return []

        items_text = ""
        for i, res in enumerate(candidates):
            items_text += f"ID: {i} | æ ‡é¢˜: ã€Š{res['title']}ã€‹ | ç®€ä»‹: {res['display_text'][:200]}\n"

        rerank_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å½±è§†æ¨èå®˜ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œå¯¹å€™é€‰å‰§é›†è¿›è¡Œç›¸å…³æ€§æ‰“åˆ†ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š"{query}"

å€™é€‰åˆ—è¡¨ï¼š
{items_text}

ä»»åŠ¡è¦æ±‚ï¼š
1. ä¸¥æ ¼æ ¹æ®ç”¨æˆ·éœ€æ±‚ä¸å‰§é›†å†…å®¹çš„ç›¸å…³åº¦æ‰“åˆ†ï¼ˆ0-10åˆ†ï¼‰ã€‚
2. åªè¿”å› JSON æ ¼å¼ï¼ŒåŒ…å«ä¸€ä¸ªæ•°ç»„ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å« id å’Œ scoreã€‚
3. å¦‚æœå‰§é›†å®Œå…¨ç¬¦åˆäººè®¾ï¼ˆå¦‚ç”¨æˆ·è¦çœ‹"åŒ»ç”Ÿ"ï¼Œè¯¥å‰§ä¸»è§’ç¡®å®æ˜¯åŒ»ç”Ÿï¼‰ï¼Œç»™ 9-10 åˆ†ã€‚
4. å¦‚æœåªæ˜¯èƒŒæ™¯æåˆ°æˆ–ä¸ç›¸å…³ï¼Œç»™ 0-3 åˆ†ã€‚

è¾“å‡ºç¤ºä¾‹ï¼š
[
  {{"id": 0, "score": 9.5}},
  {{"id": 1, "score": 4.0}}
]"""

        try:
            response = self.llm_client.chat.completions.create(
                model=LLM_MODEL_NAME,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼çš„è¯„åˆ†æœºå™¨ï¼Œåªè¾“å‡ºJSONæ•°æ®ã€‚"},
                    {"role": "user", "content": rerank_prompt}
                ],
                response_format={ "type": "json_object" if "qwen" in LLM_MODEL_NAME else "text" },
                temperature=0.1
            )
            
            content = response.choices[0].message.content.strip()
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            
            scores_data = json.loads(content)
            if isinstance(scores_data, dict):
                scores_list = scores_data.get("results", scores_data.get("scores", list(scores_data.values())[0]))
            else:
                scores_list = scores_data

            for item in scores_list:
                idx = int(item['id'])
                if idx < len(candidates):
                    candidates[idx]['rerank_score'] = float(item['score'])
            
            candidates.sort(key=lambda x: x.get('rerank_score', 0), reverse=True)
            return candidates[:top_k]

        except Exception as e:
            print(f"Rerank Error: {e}")
            return candidates[:top_k]

    def semantic_search(self, user_query: str, top_k: int = 5) -> Dict:
        intent_data = self._classify_intent(user_query)
        recall_top_k = 15 
        
        retriever_rich = self.rich_index.as_retriever(similarity_top_k=recall_top_k)
        retriever_basic = self.basic_index.as_retriever(similarity_top_k=recall_top_k)
        
        nodes_rich = retriever_rich.retrieve(user_query)
        nodes_basic = retriever_basic.retrieve(user_query)

        candidates = self._merge_and_rank_results(nodes_rich, nodes_basic, user_query)
        st.toast("ğŸš€ æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œç²¾å‡†æ’åº...", icon="ğŸ§ ")
        final_results = self._llm_rerank(user_query, candidates, top_k)

        return {
            "query_analysis": intent_data,
            "results": final_results,
            "user_query": user_query
        }

    def _classify_intent(self, query: str) -> Dict:
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªå½±è§†æœç´¢ä¸“å®¶ï¼Œè´Ÿè´£å°†ç”¨æˆ·æŸ¥è¯¢è§£æä¸ºæœç´¢å‚æ•°ã€‚
    
    ã€ä»»åŠ¡ã€‘
    ä»ç”¨æˆ·è¾“å…¥ä¸­æå–ä»¥ä¸‹å­—æ®µå¹¶è¿”å›JSONï¼š
    1. intent: 
       - "PERSONA": ç”¨æˆ·æåˆ°äº†ç‰¹å®šèŒä¸šã€èº«ä»½ã€äººè®¾ï¼ˆå¦‚ï¼šåŒ»ç”Ÿã€éœ¸æ€»ã€å•äº²å¦ˆå¦ˆï¼‰ã€‚
       - "SCENE": ç”¨æˆ·æåˆ°äº†å…·ä½“æƒ…èŠ‚æˆ–ååœºé¢ï¼ˆå¦‚ï¼šè·³å´–ã€é›¨ä¸­åˆ†æ‰‹ã€è¯¯ä¼šï¼‰ã€‚
       - "THEME": æ¨¡ç³Šçš„é¢˜æã€é£æ ¼æˆ–æƒ…ç»ªï¼ˆå¦‚ï¼šç”œå® ã€è™å¿ƒã€çˆ½å‰§ï¼‰ã€‚
    2. keywords: æ ¸å¿ƒå…³é”®è¯åˆ—è¡¨ã€‚
    3. occupation: æå–å‡ºçš„å…·ä½“èŒä¸šæˆ–èº«ä»½æ ‡ç­¾ï¼ˆè‹¥æ— åˆ™ä¸ºç©ºåˆ—è¡¨ï¼‰ã€‚
    
    ã€ç¤ºä¾‹ã€‘
    è¾“å…¥ï¼š"æƒ³çœ‹ç”·ä¸»æ˜¯åŒ»ç”Ÿçš„ç”œå® å‰§"
    è¿”å›ï¼š{{"intent": "PERSONA", "keywords": ["åŒ»ç”Ÿ", "ç”œå® "], "occupation": ["åŒ»ç”Ÿ"]}}
    
    è¾“å…¥ï¼š"ç”·å¥³ä¸»åœ¨é›¨ä¸­åˆ†æ‰‹çš„ååœºé¢"
    è¿”å›ï¼š{{"intent": "SCENE", "keywords": ["é›¨ä¸­åˆ†æ‰‹", "åˆ†æ‰‹"], "occupation": []}}
    
    è¾“å…¥ï¼š"{query}"
    """
    
        try:
            response = self.llm_client.chat.completions.create(
                model=LLM_MODEL_NAME,
                messages=[{"role": "user", "content": prompt}],
                response_format={ "type": "json_object" },
                temperature=0.1 
            )
            content = response.choices[0].message.content
            parsed = json.loads(content)
        
            if parsed.get("occupation") and len(parsed["occupation"]) > 0:
                parsed["intent"] = "PERSONA"
            
            print(f"ä¼˜åŒ–åçš„æ„å›¾è¯†åˆ«: {parsed}")
            return parsed
        except Exception as e:
            return {"intent": "THEME", "keywords": [query], "occupation": []}

    def _merge_and_rank_results(self, nodes_rich, nodes_basic, query):
        series_map = {}
        def process(nodes, src, boost=0.0):
            for node in nodes:
                m = node.metadata
                sid = m['series_id']
                score = node.score + boost
                
                full_text = node.text if len(node.text) > 200 else node.text
                
                if sid not in series_map:
                    series_map[sid] = {
                        "series_id": sid,
                        "title": m.get('title') or m.get('parent_title'),
                        "score": score,
                        "source_type": src,
                        "hit_type": m['type'],
                        "matched_episodes": [],
                        "display_text": full_text,
                        "year": m.get('year', 'æœªçŸ¥'),
                        "genre": m.get('genre', 'æœªçŸ¥'),
                        "region": m.get('region', 'æœªçŸ¥')
                    }
                else:
                    if score > series_map[sid]["score"]:
                        series_map[sid]["score"] = score
                    if len(full_text) > len(series_map[sid]["display_text"]):
                        series_map[sid]["display_text"] = full_text
                
                cur = series_map[sid]
                if m['type'] == 'episode':
                    cur['matched_episodes'].append({
                        "ep_number": m['ep_number'],
                        "content_snippet": node.text[:150] + "..."
                    })
        
        process(nodes_rich, "Rich", 0.1)
        process(nodes_basic, "Basic", 0.0)
        
        final_list = list(series_map.values())
        final_list.sort(key=lambda x: x['score'], reverse=True)
        return final_list

    def generate_recommendation_stream(self, query, results) -> Generator[str, None, None]:
        """æµå¼ç”Ÿæˆå™¨ï¼šå®Œç¾è¿‡æ»¤æ€è€ƒè¿‡ç¨‹"""
        if not results:
            yield "æœªæ‰¾åˆ°ç›¸å…³å‰§é›†ï¼Œè¯·å°è¯•æ¢ä¸ªæè¿°ã€‚"
            return

        ctx = "\n".join([f"- ã€Š{r['title']}ã€‹: {r['display_text'][:150]}" for r in results[:3]])
        # å¦‚æœqueryä¸­åŒ…å«å¯¹è¯å†å²ä¸Šä¸‹æ–‡ï¼ˆæ ¼å¼ï¼šä¹‹å‰é—®è¿‡:xxx | ç°åœ¨é—®:yyyï¼‰ï¼Œåˆ™æå–å¹¶æ ¼å¼åŒ–
        if " | ç°åœ¨é—®: " in query:
            parts = query.split(" | ç°åœ¨é—®: ")
            history_part = parts[0] if len(parts) > 1 else ""
            current_query = parts[1] if len(parts) > 1 else query
            if history_part:
                prompt = f"å¯¹è¯å†å²ï¼š{history_part}\n\nç”¨æˆ·ç°åœ¨é—®ï¼š{current_query}\n\næ¨èä»¥ä¸‹å‰§é›†ï¼š\n{ctx}\n\nè¦æ±‚ï¼šåŸºäºå¯¹è¯å†å²ç†è§£ç”¨æˆ·æ„å›¾ï¼Œç›´æ¥ä»¥æœ‹å‹è¯­æ°”æ¨èï¼Œä¸¥ç¦ä½¿ç”¨ <think> æ ‡ç­¾ï¼Œä¸¥ç¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œç¬¬ä¸€å¥è¯å°±è¿›å…¥ä¸»é¢˜ã€‚300å­—å·¦å³ã€‚"
            else:
                prompt = f"ç”¨æˆ·æœï¼š{current_query}\næ¨èä»¥ä¸‹å‰§é›†ï¼š\n{ctx}\n\nè¦æ±‚ï¼šç›´æ¥ä»¥æœ‹å‹è¯­æ°”æ¨èï¼Œä¸¥ç¦ä½¿ç”¨ <think> æ ‡ç­¾ï¼Œä¸¥ç¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œç¬¬ä¸€å¥è¯å°±è¿›å…¥ä¸»é¢˜ã€‚300å­—å·¦å³ã€‚"
        else:
            prompt = f"ç”¨æˆ·æœï¼š{query}\næ¨èä»¥ä¸‹å‰§é›†ï¼š\n{ctx}\n\nè¦æ±‚ï¼šç›´æ¥ä»¥æœ‹å‹è¯­æ°”æ¨èï¼Œä¸¥ç¦ä½¿ç”¨ <think> æ ‡ç­¾ï¼Œä¸¥ç¦è¾“å‡ºæ€è€ƒè¿‡ç¨‹ï¼Œç¬¬ä¸€å¥è¯å°±è¿›å…¥ä¸»é¢˜ã€‚300å­—å·¦å³ã€‚"

        try:
            stream = self.llm_client.chat.completions.create(
                model=LLM_MODEL_NAME,
                messages=[{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç›´æ¥è¾“å‡ºç»“æœçš„åŠ©æ‰‹ï¼Œä¸åºŸè¯ï¼Œä¸æ€è€ƒã€‚"},
                          {"role": "user", "content": prompt}],
                stream=True
            )

            is_thinking = False
            full_buffer = ""

            for chunk in stream:
                if not chunk.choices: continue
                content = chunk.choices[0].delta.content or ""
                full_buffer += content

                if "<think>" in full_buffer and "</think>" not in full_buffer:
                    is_thinking = True
                    continue
                
                if "</think>" in full_buffer:
                    full_buffer = full_buffer.split("</think>")[-1]
                    is_thinking = False
                    continue

                if not is_thinking and content:
                    if len(full_buffer) < 5 and (content.strip() in ["å¥½çš„", "é¦–å…ˆ", "ä¸ºæ‚¨"]):
                        continue
                    yield content

        except Exception as e:
            yield f"æ¨èç”Ÿæˆå‡ºé”™: {e}"

# ==============================================================================
# 3. Streamlit å‰ç«¯ï¼ˆä¿®æ”¹ç‰ˆï¼šæ”¯æŒå¤šé€‰ï¼‰
# ==============================================================================
st.set_page_config(page_title="æ™ºèƒ½ç”µè§†å‰§æœç´¢å¼•æ“", page_icon="ğŸ“º", layout="wide")

st.markdown("""
<style>
    /* å…¨å±€æ ·å¼ä¼˜åŒ– - æ¸…æ–°æ¸å˜èƒŒæ™¯ */
    .stApp {
        background: linear-gradient(135deg, #f5f7fa 0%, #e8f4f8 25%, #fff5f5 50%, #f0f9ff 75%, #faf5ff 100%);
        background-size: 400% 400%;
        animation: gradientShift 25s ease infinite;
        position: relative;
        z-index: 1;
    }
    
    /* èƒŒæ™¯è£…é¥°å›¾æ¡ˆ */
    .stApp::before {
        content: '';
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-image: 
            radial-gradient(circle at 15% 20%, rgba(147, 197, 253, 0.15) 0%, transparent 40%),
            radial-gradient(circle at 85% 60%, rgba(251, 191, 36, 0.12) 0%, transparent 40%),
            radial-gradient(circle at 50% 85%, rgba(196, 181, 253, 0.1) 0%, transparent 45%),
            radial-gradient(circle at 70% 15%, rgba(167, 243, 208, 0.12) 0%, transparent 40%);
        pointer-events: none;
        z-index: -1;
    }
    
    @keyframes gradientShift {
        0% { background-position: 0% 50%; }
        50% { background-position: 100% 50%; }
        100% { background-position: 0% 50%; }
    }
    
    /* ä¸»å†…å®¹åŒºåŸŸèƒŒæ™¯ */
    .main .block-container {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 24px;
        padding: 2.5rem;
        box-shadow: 0 10px 40px rgba(0, 0, 0, 0.06), 0 0 0 1px rgba(255, 255, 255, 0.8) inset;
        backdrop-filter: blur(20px);
        margin-top: 2rem;
        margin-bottom: 2rem;
        position: relative;
        z-index: 10;
        border: 1px solid rgba(255, 255, 255, 0.5);
    }
    
    /* å­—ä½“ä¼˜åŒ– */
    html, body, [class*="css"], .stMarkdown, .stText {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', 'Hiragino Sans GB', 'Microsoft YaHei', 'Helvetica Neue', Arial, sans-serif !important;
        letter-spacing: 0.3px;
        font-weight: 400;
    }
    
    /* æ–‡å­—å¤§å°å’Œè¡Œé«˜ä¼˜åŒ– */
    .stMarkdown p, .stText, p, li, span {
        font-size: 16px !important;
        line-height: 1.8 !important;
        color: #2d3748 !important;
        word-spacing: 1px;
    }
    
    /* æ ‡é¢˜æ ·å¼ä¼˜åŒ– - ç´«è‰²æ¸å˜ */
    h1 {
        background: linear-gradient(135deg, #4f46e5 0%, #6366f1 50%, #818cf8 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-weight: 800 !important;
        letter-spacing: -1px;
        margin-bottom: 0.5rem;
        font-size: 2.5rem !important;
        position: relative;
    }
    
    h1::after {
        content: '';
        position: absolute;
        bottom: -10px;
        left: 0;
        width: 60px;
        height: 4px;
        background: linear-gradient(90deg, #4f46e5, #6366f1);
        border-radius: 2px;
    }
    
    h2 {
        color: #1e293b !important;
        font-weight: 700 !important;
        letter-spacing: -0.3px;
        margin-top: 1.5rem;
        position: relative;
        padding-left: 1rem;
    }
    
    h2::before {
        content: '';
        position: absolute;
        left: 0;
        top: 50%;
        transform: translateY(-50%);
        width: 4px;
        height: 24px;
        background: linear-gradient(180deg, #4f46e5, #6366f1);
        border-radius: 2px;
    }
    
    h3, h4 {
        color: #334155 !important;
        font-weight: 600 !important;
    }
    
    /* æŒ‰é’®æ ·å¼ - ç™½è‰²èƒŒæ™¯è“ç´«è‰²æ–‡å­— */
    .stButton > button {
        font-size: 16px !important;
        font-weight: 600 !important;
        padding: 0.875rem 2.25rem !important;
        border-radius: 12px !important;
        background: #ffffff !important;
        border: 2px solid #4f46e5 !important;
        box-shadow: 0 2px 8px rgba(79, 70, 229, 0.15) !important;
        transition: all 0.2s ease !important;
        letter-spacing: 0.3px;
        color: #4f46e5 !important;
        text-shadow: none !important;
    }
    
    .stButton > button:hover {
        background: #f8fafc !important;
        border-color: #6366f1 !important;
        color: #6366f1 !important;
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(79, 70, 229, 0.25) !important;
    }
    
    .stButton > button:active {
        transform: translateY(0);
        background: #f1f5f9 !important;
        border-color: #4338ca !important;
        color: #4338ca !important;
    }
    
    /* Pills æ ·å¼ - é€‰ä¸­çŠ¶æ€çº¢è‰²è¾¹æ¡† */
    div[data-testid="stPills"] button {
        font-size: 14px !important;
        padding: 8px 18px !important;
        border-radius: 20px !important;
        font-weight: 500 !important;
        transition: all 0.2s ease !important;
        background: #f8fafc !important;
        color: #475569 !important;
        border: 1.5px solid #e2e8f0 !important;
    }
    
    div[data-testid="stPills"] button:hover:not([aria-pressed="true"]) {
        background: #f1f5f9 !important;
        border-color: #cbd5e1 !important;
        color: #334155 !important;
    }
    
    div[data-testid="stPills"] button[aria-pressed="true"] {
        background: #4f46e5 !important;
        color: #ffffff !important;
        border-color: #4f46e5 !important;
        border-width: 2px !important;
        box-shadow: 0 2px 6px rgba(79, 70, 229, 0.25) !important;
        font-weight: 600 !important;
    }
    
    div[data-testid="stPills"] button[aria-pressed="true"]:hover {
        background: #4338ca !important;
        border-color: #4338ca !important;
        color: #ffffff !important;
    }
    
    /* Tab æ ·å¼ä¼˜åŒ– - å»æ‰ä¸‹åˆ’çº¿ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        border-bottom: none !important;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 12px 12px 0 0 !important;
        padding: 12px 24px !important;
        font-weight: 500 !important;
        transition: all 0.2s ease !important;
        color: #64748b !important;
        background: transparent !important;
        border-bottom: none !important;
    }
    
    /* ç§»é™¤æ‰€æœ‰å¯èƒ½çš„çº¢è‰²å…ƒç´ å’Œä¸‹åˆ’çº¿ */
    .stTabs [data-baseweb="tab"][aria-selected="true"],
    .stTabs [aria-selected="true"] {
        background: rgba(79, 70, 229, 0.08) !important;
        color: #4f46e5 !important;
        font-weight: 600 !important;
        border-bottom: none !important;
        box-shadow: none !important;
        border-color: transparent !important;
    }
    
    /* ç§»é™¤æ‰€æœ‰ä¼ªå…ƒç´ çš„çº¢è‰² */
    .stTabs [data-baseweb="tab"]::before,
    .stTabs [data-baseweb="tab"]::after,
    .stTabs [data-baseweb="tab"][aria-selected="true"]::before,
    .stTabs [data-baseweb="tab"][aria-selected="true"]::after {
        background: none !important;
        border: none !important;
        border-color: transparent !important;
        display: none !important;
    }
    
    /* è¦†ç›–å†…éƒ¨å…ƒç´ çš„çº¢è‰² */
    .stTabs [data-baseweb="tab"] * {
        border-color: inherit !important;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        color: #4f46e5 !important;
        background: rgba(79, 70, 229, 0.05) !important;
    }
    
    /* å¼ºåˆ¶è¦†ç›–ä»»ä½•çº¢è‰²æ ·å¼ */
    .stTabs [data-baseweb="tab"][aria-selected="true"] span,
    .stTabs [data-baseweb="tab"][aria-selected="true"] div {
        color: #4f46e5 !important;
        border-color: #4f46e5 !important;
    }
    
    /* å®¹å™¨è¾¹æ¡†ç¾åŒ– */
    [data-testid="stHorizontalBlock"] > div[data-testid="column"],
    [data-baseweb="card"] {
        background: rgba(255, 255, 255, 0.9) !important;
        border-radius: 16px !important;
        padding: 1.25rem !important;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.06), 0 0 0 1px rgba(0, 0, 0, 0.04) !important;
        transition: all 0.3s ease !important;
        border: 1px solid rgba(255, 255, 255, 0.8) !important;
    }
    
    /* è¾“å…¥æ¡†ä¼˜åŒ– */
    .stTextArea textarea, .stTextInput input {
        border-radius: 12px !important;
        border: 2px solid #e2e8f0 !important;
        font-size: 15px !important;
        line-height: 1.7 !important;
        padding: 14px 16px !important;
        background: rgba(255, 255, 255, 0.95) !important;
        transition: all 0.3s ease !important;
    }
    
    .stTextArea textarea:focus, .stTextInput input:focus {
        border-color: #4f46e5 !important;
        box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.1) !important;
        outline: none !important;
    }
    
    /* å›¾ç‰‡åœ†è§’ */
    .stImage img {
        border-radius: 16px !important;
        box-shadow: 0 8px 24px rgba(0, 0, 0, 0.12), 0 0 0 1px rgba(0, 0, 0, 0.05) !important;
    }
    
    /* åˆ†éš”çº¿ */
    hr {
        margin: 2.5rem 0 !important;
        border: none !important;
        height: 2px !important;
        background: linear-gradient(90deg, transparent, #e2e8f0, #cbd5e1, #e2e8f0, transparent) !important;
    }
    
    /* Caption æ ·å¼ */
    .stCaption {
        color: #64748b !important;
        font-size: 14px !important;
        font-style: normal !important;
        font-weight: 500 !important;
    }
    
    /* ç¡®ä¿æ‰€æœ‰å†…å®¹å¯è§ */
    .main, .main > div, .main > div > div,
    [data-testid="stAppViewContainer"], 
    [data-testid="stHeader"], [data-testid="stToolbar"] {
        position: relative !important;
        z-index: 10 !important;
    }
</style>
""", unsafe_allow_html=True)

# ç¾åŒ–æ ‡é¢˜
st.markdown("""
<div style="text-align: center; padding: 1rem 0 2rem 0;">
    <h1 style="margin-bottom: 0.5rem;">æ™ºèƒ½ç”µè§†å‰§æœç´¢å¼•æ“</h1>
    <p style="font-size: 1.1rem; color: #64748b; margin: 0.5rem 0; font-weight: 500;">
        ç»“åˆ SQL ä¼ ç»Ÿæ£€ç´¢ä¸ LLM è¯­ä¹‰ç†è§£çš„æ–°ä¸€ä»£æ£€ç´¢ç³»ç»Ÿ
    </p>
    <div style="display: flex; justify-content: center; gap: 2rem; margin-top: 1rem; color: #94a3b8; font-size: 0.9rem;">
        <span>æ™ºèƒ½æ¨è</span>
        <span>â€¢</span>
        <span>ç²¾å‡†åŒ¹é…</span>
        <span>â€¢</span>
        <span>è¯­ä¹‰ç†è§£</span>
    </div>
</div>
""", unsafe_allow_html=True)
st.divider()

@st.cache_resource
def load_retriever():
    try:
        return SmartTVRetriever()
    except Exception as e:
        st.error(f"âŒ åç«¯åŠ è½½å¤±è´¥: {e}")
        return None

retriever = load_retriever()
if not retriever: st.stop()

tab1, tab2 = st.tabs(["ä¼ ç»Ÿç­›é€‰", "æ™ºèƒ½æœç´¢"])

# --- Tab 1: ä¼ ç»Ÿç­›é€‰ï¼ˆä¿®æ”¹ç‰ˆï¼šæ”¯æŒå¤šé€‰ï¼‰---
with tab1:
    st.subheader("ç²¾å‡†å¤šç»´ç­›é€‰")
    st.caption("æ”¯æŒå¤šé€‰ï¼ç‚¹å‡»æ ‡ç­¾å³å¯é€‰ä¸­/å–æ¶ˆï¼Œé€‰æ‹©ã€Œå…¨éƒ¨ã€å°†æ¸…é™¤å…¶ä»–é€‰é¡¹")
    
    YEAR_OPTIONS = ["å…¨éƒ¨", "2025", "2024", "2023", "2022", "2021", "2020", "2019", "2018", "æ›´æ—©"]
    GENRE_OPTIONS = ["å…¨éƒ¨", "å¤è£…", "çˆ±æƒ…", "æ‚¬ç–‘", "åŠ¨ä½œ", "å‰§æƒ…", "å–œå‰§", "å¥‡å¹»", "æ­¦ä¾ ", "é’æ˜¥", "æˆ˜äº‰", "æ ¡å›­", "åŠ±å¿—", "é©å‘½", "ä¹¡æ‘", "è­¦åŒª", "ææ€–", "å†’é™©", "æƒŠæ‚š", "ç¥è¯é­”å¹»", "è¨€æƒ…"]
    REGION_OPTIONS = ["å…¨éƒ¨", "ä¸­å›½å¤§é™†", "ä¸­å›½é¦™æ¸¯", "ç¾å›½", "éŸ©å›½", "æ—¥æœ¬", "è‹±å›½"]

    c1, c2 = st.columns([3, 1])
    with c1:
        # ä½¿ç”¨ selection_mode="multi" æ”¯æŒå¤šé€‰ï¼Œé»˜è®¤é€‰ä¸­"å…¨éƒ¨"
        s_years = st.pills("å¹´ä»½ï¼ˆå¯å¤šé€‰ï¼‰", YEAR_OPTIONS, selection_mode="multi", default=["å…¨éƒ¨"], key="py")
        s_genres = st.pills("ç±»å‹ï¼ˆå¯å¤šé€‰ï¼‰", GENRE_OPTIONS, selection_mode="multi", default=["å…¨éƒ¨"], key="pg")
        s_regions = st.pills("åœ°åŒºï¼ˆå¯å¤šé€‰ï¼‰", REGION_OPTIONS, selection_mode="multi", default=["å…¨éƒ¨"], key="pr")
    with c2:
        limit = st.slider("æ˜¾ç¤ºæ•°é‡", 1, 50, 10, key="limit")
        st.write("")
        btn_filter = st.button("ç«‹å³ç­›é€‰", type="primary")

    if btn_filter:
        st.divider()
        
        # å¤„ç†"å…¨éƒ¨"é€»è¾‘ï¼šå¦‚æœé€‰äº†"å…¨éƒ¨"ï¼Œåˆ™å¿½ç•¥è¯¥ç»´åº¦çš„å…¶ä»–é€‰é¡¹
        query_years = None
        if s_years and "å…¨éƒ¨" not in s_years:
            query_years = list(s_years)
        
        query_genres = None
        if s_genres and "å…¨éƒ¨" not in s_genres:
            query_genres = list(s_genres)
        
        query_regions = None
        if s_regions and "å…¨éƒ¨" not in s_regions:
            query_regions = list(s_regions)

        # æ˜¾ç¤ºå½“å‰ç­›é€‰æ¡ä»¶
        filter_info = []
        if query_years:
            filter_info.append(f"å¹´ä»½: {', '.join(query_years)}")
        if query_genres:
            filter_info.append(f"ç±»å‹: {', '.join(query_genres)}")
        if query_regions:
            filter_info.append(f"åœ°åŒº: {', '.join(query_regions)}")
        
        if filter_info:
            st.info(f"å½“å‰ç­›é€‰æ¡ä»¶ï¼š{' | '.join(filter_info)}")
        else:
            st.info("å½“å‰ç­›é€‰æ¡ä»¶ï¼šå…¨éƒ¨")

        with st.spinner("æ­£åœ¨æ£€ç´¢..."):
            results = retriever.filter_search(query_years, query_genres, query_regions, limit)
            if results:
                st.success(f"æ‰¾åˆ° {len(results)} éƒ¨ä½œå“")
                for r in results:
                    with st.container(border=True):
                        col_img, col_txt = st.columns([1, 4])
                        with col_img:
                            url = fetch_poster_url(r['title'])
                            st.image(url)
                        with col_txt:
                            st.markdown(f"### ã€Š{r['title']}ã€‹")
                            st.markdown(f"**å¹´ä»½:** `{r['year']}` | **åœ°åŒº:** `{r['region']}` | **ç±»å‹:** `{r['genre']}`")
                            
                            actors = r.get('actors', 'æš‚æ— æ¼”å‘˜ä¿¡æ¯')
                            desc = r.get('description', 'æš‚æ— ç®€ä»‹')
                            short_desc = desc[:120] + "..." if len(desc) > 120 else desc
                            
                            st.markdown(f"**ä¸»æ¼”:** {actors}")
                            st.markdown(f"**ç®€ä»‹:** {short_desc}")
                            
                            with st.expander("æŸ¥çœ‹å®Œæ•´ç®€ä»‹"):
                                st.write(desc)
            else:
                st.warning("æœªæ‰¾åˆ°åŒ¹é…å‰§é›†ï¼Œè¯·å°è¯•è°ƒæ•´ç­›é€‰æ¡ä»¶ã€‚")

# --- Tab 2: æ™ºèƒ½æœç´¢ï¼ˆå¤šè½®å¯¹è¯ç‰ˆæœ¬ï¼‰---
with tab2:
    st.subheader("è¯­ä¹‰ç†è§£æœç´¢")
    
    # åˆå§‹åŒ–å¯¹è¯ä¼šè¯ç®¡ç†ï¼ˆç±»ä¼¼ChatGPTçš„è®¾è®¡ï¼‰
    if "conversations" not in st.session_state:
        st.session_state.conversations = {}
    if "current_conversation_id" not in st.session_state:
        st.session_state.current_conversation_id = None
    if "conversation_counter" not in st.session_state:
        st.session_state.conversation_counter = 0
    if "scroll_to_top" not in st.session_state:
        st.session_state.scroll_to_top = False
    
    # è‡ªåŠ¨æ»šåŠ¨åˆ°é¡¶éƒ¨
    if st.session_state.scroll_to_top:
        st.markdown("""
        <script>
            window.parent.scrollTo({ top: 0, behavior: 'smooth' });
        </script>
        """, unsafe_allow_html=True)
        st.session_state.scroll_to_top = False
    
    # è·å–å½“å‰å¯¹è¯çš„æ‰€æœ‰è½®æ¬¡
    current_turns = []
    if st.session_state.current_conversation_id and st.session_state.current_conversation_id in st.session_state.conversations:
        current_turns = st.session_state.conversations[st.session_state.current_conversation_id]
    
    # æ˜¾ç¤ºå½“å‰å¯¹è¯çš„æ‰€æœ‰è½®æ¬¡ï¼ˆç±»ä¼¼ChatGPTçš„å¯¹è¯æµï¼‰
    if current_turns:
        for idx, turn in enumerate(current_turns):
            is_last_turn = (idx == len(current_turns) - 1)  # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€åä¸€è½®ï¼ˆæœ€æ–°çš„ä¸€è½®ï¼‰
            query_preview = clean_html_tags(turn.get('query', ''))[:30]  # é¢„è§ˆæ–‡æœ¬ç”¨äºexpanderæ ‡ç­¾
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€è½®ï¼Œä½¿ç”¨expanderåŒ…è£¹ï¼ˆé»˜è®¤æŠ˜å ï¼‰
            if not is_last_turn:
                with st.expander(f"ğŸ“ ç¬¬{idx+1}è½®å¯¹è¯: {query_preview}...", expanded=False):
                    _render_turn_content(turn)
            else:
                # æœ€åä¸€è½®ç›´æ¥æ˜¾ç¤ºï¼ˆå±•å¼€ï¼‰
                _render_turn_content(turn)
    else:
        # é¦–æ¬¡è¿›å…¥ï¼Œæ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
        st.markdown("""
        <div style="text-align: center; padding: 3rem 1rem; color: #64748b;">
            <h3 style="color: #1e293b;">å¼€å§‹æ–°çš„æœç´¢å¯¹è¯</h3>
            <p>æè¿°ä½ æƒ³çœ‹çš„å‰§é›†ï¼Œä¾‹å¦‚ï¼š"ç”·ä¸»æ˜¯åŒ»ç”Ÿçš„ç°ä»£å‰§"ã€"æƒ³çœ‹çœ‹ç”œå® å‰§"ç­‰</p>
        </div>
        """, unsafe_allow_html=True)
    
    # è¾“å…¥åŒºåŸŸï¼ˆå›ºå®šåœ¨åº•éƒ¨ï¼Œç±»ä¼¼ChatGPTï¼‰
    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # æ–°å¯¹è¯æŒ‰é’®
    if st.button("â• æ–°å¯¹è¯", help="å¼€å§‹å…¨æ–°çš„å¯¹è¯ä¼šè¯", key="new_conversation_btn"):
        # åˆ›å»ºæ–°å¯¹è¯ä¼šè¯ï¼ˆæ¸…ç©ºå½“å‰ï¼Œå¼€å§‹å…¨æ–°å¯¹è¯ï¼‰
        st.session_state.conversation_counter += 1
        st.session_state.current_conversation_id = f"conv_{st.session_state.conversation_counter}"
        st.session_state.conversations[st.session_state.current_conversation_id] = []
        st.session_state.scroll_to_top = True
        st.rerun()
    
    # è¾“å…¥æ¡†å’Œå‘é€æŒ‰é’®
    with st.container():
        col_input1, col_input2, col_input3 = st.columns([6, 1.5, 1])
        with col_input1:
            query = st.text_area(
                "", 
                placeholder="æè¿°ä½ çš„éœ€æ±‚...",
                height=60,
                key="semantic_query_input",
                label_visibility="collapsed"
            )
        with col_input2:
            top_k = st.number_input("æ¨èæ•°é‡", 1, 20, 3, key="semantic_top_k", label_visibility="visible")
        with col_input3:
            st.write("")  # æ·»åŠ ç©ºç™½è¡Œå¯¹é½
            st.write("")  # æ·»åŠ ç©ºç™½è¡Œå¯¹é½
            btn_search = st.button("å‘é€", type="primary", key="send_search_btn")
    
    # å¤„ç†æœç´¢ï¼ˆåœ¨å½“å‰å¯¹è¯ä¸­æ·»åŠ æ–°è½®æ¬¡ï¼‰
    if btn_search and query:
        try:
            # å¦‚æœæ²¡æœ‰å½“å‰å¯¹è¯ï¼Œåˆ›å»ºæ–°å¯¹è¯
            if not st.session_state.current_conversation_id:
                st.session_state.conversation_counter += 1
                st.session_state.current_conversation_id = f"conv_{st.session_state.conversation_counter}"
                st.session_state.conversations[st.session_state.current_conversation_id] = []
            
            # æ„å»ºå¢å¼ºçš„æŸ¥è¯¢ï¼ˆç»“åˆå½“å‰å¯¹è¯çš„å†å²ä¸Šä¸‹æ–‡ï¼‰
            enhanced_query = query
            conversation_context = ""  # ç”¨äºæ¨èç”Ÿæˆçš„ä¸Šä¸‹æ–‡
            current_turns = st.session_state.conversations.get(st.session_state.current_conversation_id, [])
            if current_turns:
                # æ„å»ºå®Œæ•´çš„å¯¹è¯å†å²ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«ä¹‹å‰çš„æ‰€æœ‰è½®æ¬¡ï¼‰
                context_parts = []
                for prev_turn in current_turns[-3:]:  # å–æœ€è¿‘3è½®ä½œä¸ºä¸Šä¸‹æ–‡
                    prev_query = prev_turn.get('query', '')
                    if prev_query:
                        context_parts.append(f"ä¹‹å‰é—®è¿‡: {prev_query}")
                if context_parts:
                    conversation_context = " | ".join(context_parts)
                    # ç”¨äºæœç´¢çš„å¢å¼ºæŸ¥è¯¢ï¼ˆç®€å•æ‹¼æ¥æœ€è¿‘çš„æŸ¥è¯¢ï¼‰
                    previous_queries = [turn['query'] for turn in current_turns[-2:]]
                    context = " ".join(previous_queries)
                    enhanced_query = f"{context} {query}"
            
            with st.spinner("AI æ­£åœ¨åˆ†ææ‚¨çš„éœ€æ±‚..."):
                res = retriever.semantic_search(enhanced_query, top_k)
            
            # ç”Ÿæˆæ¨èè¯­ï¼ˆä½¿ç”¨å¸¦ä¸Šä¸‹æ–‡çš„æŸ¥è¯¢ï¼‰
            recommendation_text = ""
            try:
                # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œå°†ä¸Šä¸‹æ–‡ä¿¡æ¯ä¼ é€’ç»™æ¨èç”Ÿæˆ
                query_for_recommendation = query
                if conversation_context:
                    query_for_recommendation = f"{conversation_context} | ç°åœ¨é—®: {query}"
                
                for chunk in retriever.generate_recommendation_stream(query_for_recommendation, res.get("results", [])):
                    recommendation_text += chunk
            except:
                recommendation_text = "æ ¹æ®æ‚¨çš„æœç´¢ï¼Œä¸ºæ‚¨æ‰¾åˆ°äº†ä»¥ä¸‹ç›¸å…³å‰§é›†ã€‚"
            
            # æ¸…ç†æ¨èæ–‡æœ¬ä¸­çš„HTMLæ ‡ç­¾
            recommendation_text = clean_html_tags(recommendation_text)
            # æ¸…ç†æŸ¥è¯¢æ–‡æœ¬
            query_clean = clean_html_tags(query)
            
            # åœ¨å½“å‰å¯¹è¯ä¸­æ·»åŠ æ–°è½®æ¬¡
            turn_data = {
                "query": query_clean,
                "recommendation": recommendation_text,
                "results": res.get("results", [])
            }
            st.session_state.conversations[st.session_state.current_conversation_id].append(turn_data)
            
            # æ ‡è®°éœ€è¦æ»šåŠ¨åˆ°é¡¶éƒ¨
            st.session_state.scroll_to_top = True
            
            # è‡ªåŠ¨åˆ·æ–°æ˜¾ç¤º
            st.rerun()
            
        except Exception as e:
            st.error(f"æœç´¢è¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                st.code(traceback.format_exc())